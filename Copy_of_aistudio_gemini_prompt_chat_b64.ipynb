{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2023 Google LLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKwyTRdwB8aW"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlE8UqxrDIez"
      },
      "source": [
        "### Install & import\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cZiU4TKzznh9"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kWIuwKG2_oWE"
      },
      "outputs": [],
      "source": [
        "# import necessary modules.\n",
        "import google.generativeai as genai\n",
        "import json\n",
        "import base64\n",
        "import pathlib\n",
        "import pprint\n",
        "import requests\n",
        "import mimetypes\n",
        "from IPython.display import Markdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fet3lFjdKHEM"
      },
      "source": [
        "## Set the API key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoRWILAtCzBE"
      },
      "source": [
        "Add your API_KEY to the secrets manager in the left pannel \"ðŸ”‘\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LaLCwNlkCyQd"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "API_KEY=userdata.get('API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_SvYoR3WCeKr"
      },
      "outputs": [],
      "source": [
        "# Configure the client library by providing your API key.\n",
        "genai.configure(api_key=API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weo-o73WDpdm"
      },
      "source": [
        "### Parse the arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uIog-0SyDuIF"
      },
      "outputs": [],
      "source": [
        "model = \"gemini-pro\" # @param {isTemplate: true}\n",
        "contents_b64 = \"W3sicm9sZSI6InVzZXIiLCAicGFydHMiIDogW3sidGV4dCI6ICJoZWxsbyJ9XX0sIHsicm9sZSI6ICJtb2RlbCIsICJwYXJ0cyI6IFt7InRleHQiOiAiSGVsbG8hIEhvdyBjYW4gSSBhc3Npc3QgeW91IHRvZGF5PyJ9XX1d\" # @param {isTemplate: true}\n",
        "generation_config_b64 = \"e30=\" # @param {isTemplate: true}\n",
        "safety_settings_b64 = \"e30=\" # @param {isTemplate: true}\n",
        "user_input_b64 = 'SG93IGRvZXMgZWxlY3RyaWNpdHkgd29yaz8=' #@param {isTemplate: true}\n",
        "\n",
        "contents = json.loads(base64.b64decode(contents_b64))\n",
        "generation_config = json.loads(base64.b64decode(generation_config_b64))\n",
        "safety_settings = json.loads(base64.b64decode(safety_settings_b64))\n",
        "user_input = base64.b64decode(user_input_b64).decode()\n",
        "stream = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wBS8xNhN0x62",
        "outputId": "87c272c8-8122-4c64-eab7-f2d9fafc3c46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'user', 'parts': [{'text': 'hello'}]},\n",
              " {'role': 'model', 'parts': [{'text': 'Hello! How can I assist you today?'}]}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "contents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1681593ef561",
        "outputId": "9ac7e54e-63a1-4989-c293-8aa7739a6007",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "generation_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "a2c31f8f1894",
        "outputId": "950a24ee-9046-4c1c-c8a5-45e5e5b9114c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "safety_settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4d17bac9fefc",
        "outputId": "aff92de6-f47a-48a8-c4f7-7803e0b6b71d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'How does electricity work?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "user_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7zAD69vE92b"
      },
      "source": [
        "### Call the API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LB2LxPmAB95V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "outputId": "b67a009b-5bbe-472b-9728-08a05a11df96"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "StopCandidateException",
          "evalue": "finish_reason: RECITATION\nindex: 0\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStopCandidateException\u001b[0m                    Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m gemini \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mGenerativeModel(model_name\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m      4\u001b[0m chat \u001b[38;5;241m=\u001b[39m gemini\u001b[38;5;241m.\u001b[39mstart_chat(history\u001b[38;5;241m=\u001b[39mcontents)\n\u001b[0;32m----> 6\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py:384\u001b[0m, in \u001b[0;36mChatSession.send_message\u001b[0;34m(self, content, generation_config, safety_settings, stream, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcandidates[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mfinish_reason \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m    380\u001b[0m         glm\u001b[38;5;241m.\u001b[39mCandidate\u001b[38;5;241m.\u001b[39mFinishReason\u001b[38;5;241m.\u001b[39mFINISH_REASON_UNSPECIFIED,\n\u001b[1;32m    381\u001b[0m         glm\u001b[38;5;241m.\u001b[39mCandidate\u001b[38;5;241m.\u001b[39mFinishReason\u001b[38;5;241m.\u001b[39mSTOP,\n\u001b[1;32m    382\u001b[0m         glm\u001b[38;5;241m.\u001b[39mCandidate\u001b[38;5;241m.\u001b[39mFinishReason\u001b[38;5;241m.\u001b[39mMAX_TOKENS,\n\u001b[1;32m    383\u001b[0m     ):\n\u001b[0;32m--> 384\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mStopCandidateException(response\u001b[38;5;241m.\u001b[39mcandidates[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_sent \u001b[38;5;241m=\u001b[39m content\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_received \u001b[38;5;241m=\u001b[39m response\n",
            "\u001b[0;31mStopCandidateException\u001b[0m: finish_reason: RECITATION\nindex: 0\n"
          ]
        }
      ],
      "source": [
        "# Call the model and print the response.\n",
        "gemini = genai.GenerativeModel(model_name=model)\n",
        "\n",
        "chat = gemini.start_chat(history=contents)\n",
        "\n",
        "response = chat.send_message(\n",
        "    user_input,\n",
        "    stream=stream)"
      ]
    },
    {
      "source": [
        "import google.generativeai as genai\n",
        "import google.generativeai.types as glm"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "O2GwfBbIy4AW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "source": [
        "print(chat)\n",
        "print(gemini)\n",
        "print(model)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVM140xxy5h1",
        "outputId": "1e759fda-6a68-43ba-a934-a309fba92ea5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<google.generativeai.generative_models.ChatSession object at 0x7b1d32bb2980>\n",
            " genai.GenerativeModel(\n",
            "   model_name='models/gemini-pro',\n",
            "   generation_config={}.\n",
            "   safety_settings={}\n",
            ")\n",
            "gemini-pro\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from genai import GenerativeModel"
      ],
      "metadata": {
        "id": "qVcmg_5wxFwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lm3RXwYuGtZK"
      },
      "outputs": [],
      "source": [
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbKuUc3NGxYD"
      },
      "outputs": [],
      "source": [
        "response.prompt_feedback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLAaIq3kgwwJ"
      },
      "outputs": [],
      "source": [
        "response.candidates"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}